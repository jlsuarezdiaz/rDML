% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/dml.R
\name{NCMC}
\alias{NCMC}
\title{Nearest Class with Multiple Centroids distance metric learner (NCMC).}
\usage{
NCMC(num_dims = NULL, centroids_num = 3, learning_rate = "adaptive",
  eta0 = 0.3, initial_transform = NULL, max_iter = 300,
  tol = 1e-15, prec = 1e-15, descent_method = "SGD",
  eta_thres = 1e-14, learn_inc = 1.01, learn_dec = 0.5, ...)
}
\arguments{
\item{num_dims}{Desired value for dimensionality reduction. If None, the dimension of transformed data will be the same as the original. Integer.}

\item{centroids_num}{If it is a list, it must have the same size as the number of classes. In this case, i-th item will be the number of
centroids to take in the i-th class. If it is an int, every class will have the same number of centroids.}

\item{learning_rate}{Type of learning rate update for gradient descent. Possible values are:
- 'adaptive' : the learning rate will increase if the gradient step is succesful, else it will decrease.
- 'constant' : the learning rate will be constant during all the gradient steps.}

\item{eta0}{The initial value for learning rate.}

\item{initial_transform}{If array or matrix that will represent the starting linear map for gradient descent, where d is the number of features,
and d' is the dimension specified in num_dims.
If None, euclidean distance will be used. If a string, the following values are allowed:
- 'euclidean' : the euclidean distance.
- 'scale' : a diagonal matrix that normalizes each attribute according to its range will be used.}

\item{max_iter}{Maximum number of iterations of gradient descent. Integer.}

\item{tol}{Tolerance stop criterion (difference between two iterations). Float.}

\item{prec}{Precision stop criterion (gradient norm). Float.}

\item{descent_method}{The descent method to use. Allowed values are:
- 'SGD' : stochastic gradient descent.
- 'BGD' : batch gradient descent.}

\item{eta_thres}{A learning rate threshold stop criterion. Float.}

\item{learn_inc}{Increase factor for learning rate. Ignored if learning_rate is not 'adaptive'. Float.}

\item{learn_dec}{Decrease factor for learning rate. Ignored if learning_rate is not 'adaptive'. Float.}

\item{...}{Aditional argument for Scikit-Learn K-Means.}
}
\value{
The NCMC transformer, structured as a named list.
}
\description{
A distance metric learning algorithm to improve the nearest class with multiple centroids classifier.
}
\references{
Thomas Mensink et al. “Metric learning for large scale image classification: Generalizing to new
            classes at near-zero cost”. In: Computer Vision–ECCV 2012. Springer, 2012, pages 488-501.
}
